{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import betaln\n",
    "from scipy.stats import beta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoothing.constants import (\n",
    "    MIN_STARTS_THRESHOLD,\n",
    "    INITIAL_PARAMS,\n",
    "    BOUNDS,\n",
    "    N_SAMPLES,\n",
    "    N_TRIALS,\n",
    ")\n",
    "\n",
    "from utils.constants import OUTPUT_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.load_data import load_data\n",
    "BADLY_BEATEN_THRESHOLD = 2900 # 99th percentile\n",
    "\n",
    "COLS_FOR_SMOOTHING = ['dnf', 'scratched', 'vet_scratched', 'badly_beaten', 'breakdown']\n",
    "DENOMINATORS = {\n",
    "    'dnf': 'n_starts',\n",
    "    'scratched': 'n_entries',\n",
    "    'vet_scratched': 'n_entries',\n",
    "    'badly_beaten': 'n_starts',\n",
    "    'breakdown': 'n_starts'\n",
    "}\n",
    "\n",
    "DISPLAY_NAMES = {\n",
    "    'dnf': 'DNF',\n",
    "    'scratched': 'Scratched',\n",
    "    'vet_scratched': 'Vet Scratched',\n",
    "    'badly_beaten': 'Badly Beaten',\n",
    "    'breakdown': 'Breakdown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.constants import YEARS_TO_MODEL, DATA_BUCKET\n",
    "\n",
    "\n",
    "def load_data(local: bool, load_2020: bool) -> pd.DataFrame:\n",
    "    if local:\n",
    "        df = pd.read_csv('/users/jameshull/documents/github/hisa-data/races_2023.csv', nrows=10000)\n",
    "    \n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        for yr in YEARS_TO_MODEL:\n",
    "            if yr == 2020 and not load_2020:\n",
    "                continue\n",
    "            data_key = f'races_{yr}.csv' \n",
    "            data_location = 's3://{}/{}'.format(DATA_BUCKET, data_key) \n",
    "            df_yr = pd.read_csv(data_location) \n",
    "            df = pd.concat([df, df_yr], ignore_index=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnf(df: pd.DataFrame) -> pd.Series:\n",
    "    dnf = np.where(\n",
    "            df['length_behind_at_finish'] > 9000,\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "    return pd.Series(dnf, name='dnf')\n",
    "\n",
    "\n",
    "\n",
    "def get_scratches(df: pd.DataFrame) -> pd.Series:\n",
    "    scratched = np.where(\n",
    "            df['scratch_indicator'] == 'Y',\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "    vets_scratch = np.where(\n",
    "        (df['scratch_indicator'] == 'Y') & (df['scratch_reason'].isin(['I', 'J', 'N', 'U', 'V', 'Z'])),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return pd.Series(scratched, name='scratched'), pd.Series(vets_scratch, name='vet_scratched')\n",
    "    \n",
    "\n",
    "def get_medication(df: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    lasix = np.where(\n",
    "        df['medication'].str.contains('L'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    bute = np.where(\n",
    "        df['medication'].str.contains('B'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return pd.Series(lasix, name='lasix'), pd.Series(bute, name='bute')\n",
    "    \n",
    "\n",
    "def get_badly_beaten(df: pd.DataFrame) -> pd.Series:\n",
    "    badly_beaten = np.where(\n",
    "        (df['length_behind_at_finish'] > BADLY_BEATEN_THRESHOLD) & (df['dnf'] == 0),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return pd.Series(badly_beaten, name='badly_beaten')\n",
    "\n",
    "\n",
    "def get_breakdown(df: pd.DataFrame) -> pd.Series:\n",
    "    breakdown = np.where(\n",
    "        (df['long_comment'].str.contains('vanned')) & (df['dnf'] == 1), \n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return pd.Series(breakdown, name='breakdown')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_trainer_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    trainer_entries = df.groupby('trainer_id').agg({\n",
    "        'registration_number': 'nunique',\n",
    "        'race_date': 'count'\n",
    "    }).reset_index().rename(columns={\n",
    "        'registration_number': 'n_horses', \n",
    "        'race_date': 'n_entries'\n",
    "    })\n",
    "\n",
    "    starts = df[df['scratched'] == 0]\n",
    "    trainer_starts = starts.groupby('trainer_id').agg({\n",
    "        'race_date': 'count'\n",
    "    }).reset_index().rename(columns={\n",
    "        'race_date': 'n_starts'\n",
    "    })\n",
    "\n",
    "    trainer_stats = df.groupby('trainer_id').agg({\n",
    "        'dnf': 'sum',\n",
    "        'scratched': 'sum',\n",
    "        'vet_scratched': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "        'breakdown': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    trainer_data = trainer_entries.merge(trainer_starts, on='trainer_id', how='inner')\n",
    "    trainer_data = trainer_data.merge(trainer_stats, on='trainer_id', how='inner')\n",
    "    trainer_data = trainer_data.fillna(0)\n",
    "\n",
    "    for col in COLS_FOR_SMOOTHING:\n",
    "        trainer_data[f'{col}_pct'] = trainer_data[col] / trainer_data[DENOMINATORS[col]]\n",
    "\n",
    "\n",
    "    return trainer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_likelihood(params: Tuple[float], x: pd.Series, total: pd.Series) -> float:\n",
    "    alpha0, beta0 = params\n",
    "    log_prob = (\n",
    "        betaln(x + alpha0, total - x + beta0)\n",
    "        - betaln(alpha0, beta0)\n",
    "        - betaln(x + 1, total - x + 1)\n",
    "    )\n",
    "\n",
    "    return -np.sum(log_prob)\n",
    "\n",
    "\n",
    "def calculate_beta_binom_params(df: pd.DataFrame, x_column: str, total_column: str) -> Tuple[float, float]:\n",
    "    \n",
    "    df_threshold = df[df[\"n_starts\"] >= MIN_STARTS_THRESHOLD]\n",
    "    x = df_threshold[x_column].values\n",
    "    total = df_threshold[total_column].values\n",
    "\n",
    "    result = minimize(\n",
    "        log_likelihood,\n",
    "        INITIAL_PARAMS,\n",
    "        args=(x, total),\n",
    "        method=\"L-BFGS-B\",\n",
    "        bounds=BOUNDS,\n",
    "    )\n",
    "\n",
    "    alpha0, beta0 = result.x\n",
    "\n",
    "    return alpha0, beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smoothing_params(df: pd.DataFrame) -> Dict:\n",
    "    smoothing_params = {}\n",
    "    for col in COLS_FOR_SMOOTHING:\n",
    "        alpha0, beta0 = calculate_beta_binom_params(df, f'{col}', DENOMINATORS[col])\n",
    "        smoothing_params[col] = {\n",
    "            'alpha0': alpha0,\n",
    "            'beta0': beta0\n",
    "        }\n",
    "\n",
    "    with open('output/smoothing/smoothing_params.json', 'w') as f:\n",
    "        json.dump(smoothing_params, f)\n",
    "\n",
    "    return smoothing_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smoothing_params() -> Dict:\n",
    "    with open('output/smoothing/smoothing_params.json', 'r') as f:\n",
    "        smoothing_params = json.load(f)\n",
    "\n",
    "    return smoothing_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smoothed_rates(df: pd.DataFrame, smoothing_params: Dict) -> pd.DataFrame:\n",
    "    for c in COLS_FOR_SMOOTHING:\n",
    "        alpha0 = smoothing_params[c]['alpha0']\n",
    "        beta0 = smoothing_params[c]['beta0']\n",
    "\n",
    "        df[f'{c}_pct_smoothed'] = (df[c] + alpha0) / (df[DENOMINATORS[c]] + alpha0 + beta0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_beta_binomial_samples(\n",
    "    n: int, alpha0: float, beta0: float, size: int\n",
    ") -> np.ndarray:\n",
    "    p = np.random.beta(alpha0, beta0, size)\n",
    "    samples = np.random.binomial(n, p, size)\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def create_sample_plot(alpha0: float, beta0: float, column_name: str) -> None:\n",
    "    samples = generate_beta_binomial_samples(N_TRIALS, alpha0, beta0, N_SAMPLES)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(\n",
    "        samples,\n",
    "        bins=np.arange(0, N_TRIALS / 10) - 0.5,\n",
    "        density=False,\n",
    "        alpha=0.75,\n",
    "        color=\"blue\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    plt.xlim(-0.05, max(samples) + 0.1*max(samples))\n",
    "    plt.xlabel(f\"{DISPLAY_NAMES[column_name]} per {N_TRIALS} starts\")\n",
    "    plt.ylabel(\"Count of Trainers\")\n",
    "    plt.title(f\"Simulated Number of {DISPLAY_NAMES[column_name]}\")\n",
    "    plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"output/smoothing/{column_name}_simulation_per_1000.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_ranking_plot(df: pd.DataFrame, alpha0: float, beta0: float, column_name: str) -> None:\n",
    "    df = df.dropna(subset=[f\"{column_name}_pct\", DENOMINATORS[column_name], f\"{column_name}_pct_smoothed\"])\n",
    "\n",
    "    df[\"low\"] = beta.ppf(0.025, alpha0 + df[column_name], beta0 + df[DENOMINATORS[column_name]] - df[column_name])\n",
    "    df[\"high\"] = beta.ppf(0.975, alpha0 + df[column_name], beta0 + df[DENOMINATORS[column_name]] - df[column_name])\n",
    "\n",
    "    if df.shape[0] > 10:\n",
    "        print(\"Warning: Too many trainers to plot. Showing a random sample of 10.\")\n",
    "        df = df.sample(10)\n",
    "\n",
    "    df = df.sort_values(f'{column_name}_pct_smoothed').reset_index(drop=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(\n",
    "        df[f'{column_name}_pct_smoothed'],\n",
    "        df[\"trainer_id\"].astype(str),\n",
    "        xerr=[df[f'{column_name}_pct_smoothed'] - df[\"low\"], df[\"high\"] - df[f'{column_name}_pct_smoothed']],\n",
    "        fmt=\"o\",\n",
    "        color=\"blue\",\n",
    "        ecolor=\"black\",\n",
    "        capsize=3,\n",
    "    )\n",
    "    plt.axvline(x=alpha0 / (alpha0 + beta0), color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(f\"Smoothed {DISPLAY_NAMES[column_name]} Percentage, with 95% credible interval\")\n",
    "    plt.ylabel(\"Trainer\")\n",
    "    plt.title(f\"Trainer Rankings by Smoothed {DISPLAY_NAMES[column_name]} Percentage\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.savefig(f\"output/smoothing/{column_name}_ranking_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_smoothed_scatter_plot(df: pd.DataFrame, alpha0: float, beta0: float, column_name: str) -> None:\n",
    "\n",
    "    df = df.dropna(subset=[f\"{column_name}_pct\", DENOMINATORS[column_name], f\"{column_name}_pct_smoothed\"])\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        df[f\"{column_name}_pct\"],\n",
    "        df[f\"{column_name}_pct_smoothed\"],\n",
    "        c=np.log(df[DENOMINATORS[column_name]]),\n",
    "        cmap=\"bwr\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    max_val = max(df[f'{column_name}_pct_smoothed']) + 0.01*max(df[f'{column_name}_pct_smoothed'])\n",
    "    plt.plot([0, max_val], [0, max_val], color=\"gray\", linestyle=\"--\", alpha=0.8)\n",
    "    plt.plot(\n",
    "        [0, max_val],\n",
    "        [(alpha0) / (alpha0 + beta0), (alpha0) / (alpha0 + beta0)],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    plt.xlim(-0.005, max_val)\n",
    "    plt.ylim(-0.005, max_val)\n",
    "    plt.xlabel(f\"Observed {DISPLAY_NAMES[column_name]} Rate\")\n",
    "    plt.ylabel(f\"Smoothed {DISPLAY_NAMES[column_name]} Rate\")\n",
    "    plt.title(f\"Observed vs. Smoothed {DISPLAY_NAMES[column_name]} Rate\")\n",
    "    plt.colorbar(label=\"Log Number of Starts\")\n",
    "    plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"output/smoothing/{column_name}_smoothed_scatter.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Too many trainers to plot. Showing a random sample of 10.\n",
      "Warning: Too many trainers to plot. Showing a random sample of 10.\n",
      "Warning: Too many trainers to plot. Showing a random sample of 10.\n",
      "Warning: Too many trainers to plot. Showing a random sample of 10.\n",
      "Warning: Too many trainers to plot. Showing a random sample of 10.\n"
     ]
    }
   ],
   "source": [
    "df = load_data(local=True, load_2020=False)\n",
    "df['dnf'] = get_dnf(df)\n",
    "df['scratched'], df['vet_scratched'] = get_scratches(df)\n",
    "df['lasix'], df['bute'] = get_medication(df)\n",
    "df['badly_beaten'] = get_badly_beaten(df)\n",
    "df['breakdown'] = get_breakdown(df)\n",
    "\n",
    "trainers = group_trainer_info(df)\n",
    "smoothing_params = get_smoothing_params(trainers)\n",
    "trainers = calculate_smoothed_rates(trainers, smoothing_params)\n",
    "\n",
    "for c in COLS_FOR_SMOOTHING:\n",
    "    create_smoothed_scatter_plot(trainers, smoothing_params[c]['alpha0'], smoothing_params[c]['beta0'], c)\n",
    "    create_sample_plot(smoothing_params[c]['alpha0'], smoothing_params[c]['beta0'], c)\n",
    "    create_ranking_plot(trainers, smoothing_params[c]['alpha0'], smoothing_params[c]['beta0'], c)\n",
    "    \n",
    "\n",
    "#trainers.to_csv(f's3://{OUTPUT_BUCKET}/trainer_rates_smoothed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import betaln\n",
    "from scipy.stats import beta\n",
    "\n",
    "from utils.processing import get_dnf\n",
    "from smoothing.constants import (\n",
    "    MIN_STARTS_THRESHOLD,\n",
    "    INITIAL_PARAMS,\n",
    "    BOUNDS,\n",
    "    N_SAMPLES,\n",
    "    N_TRIALS,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_ranking_plot(df: pd.DataFrame, alpha0: float, beta0: float) -> None:\n",
    "    df = df.dropna(subset=[\"dnf_pct\", \"n_starts\", \"smoothed_dnf_pct\"])\n",
    "\n",
    "    df[\"low\"] = beta.ppf(0.025, alpha0 + df[\"dnf\"], beta0 + df[\"n_starts\"] - df[\"dnf\"])\n",
    "    df[\"high\"] = beta.ppf(0.975, alpha0 + df[\"dnf\"], beta0 + df[\"n_starts\"] - df[\"dnf\"])\n",
    "\n",
    "    if df.shape[0] > 10:\n",
    "        print(\"Warning: Too many trainers to plot. Showing a random sample of 10.\")\n",
    "        df = df.sample(10)\n",
    "\n",
    "    df = df.sort_values(\"smoothed_dnf_pct\").reset_index(drop=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(\n",
    "        df[\"smoothed_dnf_pct\"],\n",
    "        df[\"trainer_id\"].astype(str),\n",
    "        xerr=[df[\"smoothed_dnf_pct\"] - df[\"low\"], df[\"high\"] - df[\"smoothed_dnf_pct\"]],\n",
    "        fmt=\"o\",\n",
    "        color=\"blue\",\n",
    "        ecolor=\"black\",\n",
    "        capsize=3,\n",
    "    )\n",
    "    plt.axvline(x=alpha0 / (alpha0 + beta0), color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Smoothed DNF Percentage, with 95% credible interval\")\n",
    "    plt.ylabel(\"Trainer\")\n",
    "    plt.title(\"Trainer Rankings by Smoothed DNF Percentage\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.savefig(\"output/smoothing/ranking_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = group_trainer_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>n_entries</th>\n",
       "      <th>n_starts</th>\n",
       "      <th>dnf</th>\n",
       "      <th>scratched</th>\n",
       "      <th>vet_scratched</th>\n",
       "      <th>badly_beaten</th>\n",
       "      <th>breakdown</th>\n",
       "      <th>dnf_pct</th>\n",
       "      <th>scratched_pct</th>\n",
       "      <th>vet_scratched_pct</th>\n",
       "      <th>badly_beaten_pct</th>\n",
       "      <th>breakdown_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trainer_id  n_horses  n_entries  n_starts  dnf  scratched  vet_scratched  \\\n",
       "0          32         1          1         1    0          0              0   \n",
       "1         171        22         44        38    0          6              4   \n",
       "\n",
       "   badly_beaten  breakdown  dnf_pct  scratched_pct  vet_scratched_pct  \\\n",
       "0             0          0      0.0       0.000000           0.000000   \n",
       "1             1          0      0.0       0.136364           0.090909   \n",
       "\n",
       "   badly_beaten_pct  breakdown_pct  \n",
       "0          0.000000            0.0  \n",
       "1          0.026316            0.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xDNF(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    scratches = df[df['scratch_indicator'] == 'Y']\n",
    "    scratches['xDNF'] = np.nan\n",
    "    racers = df[df['scratch_indicator'] != 'Y']\n",
    "    racers['xDNF'] = baseline_inference(df)\n",
    "\n",
    "    df = pd.concat([racers, scratches])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['dnf'] = np.where(\n",
    "        (df['trouble_indicator'] == 'Y') | (df['length_behind_at_finish'] == 9999),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df['scratched'] = np.where(\n",
    "        df['scratch_indicator'] == 'Y',\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['lasix'] = np.where(\n",
    "        df['medication'].str.contains('L'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['bute'] = np.where(\n",
    "        df['medication'].str.contains('B'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['badly_beaten'] = np.where(\n",
    "        (df['length_behind_at_finish'] > BADLY_BEATEN_THRESHOLD) & (df['length_behind_at_finish'] < 9000),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit exponential to df['length_behind_at_finish']\n",
    "from scipy.stats import expon\n",
    "\n",
    "params = expon.fit(df['length_behind_at_finish'])\n",
    "\n",
    "# get 95th percentile\n",
    "expon.ppf(0.95, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_race_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "    df = df.sort_values(by=['registration_number', 'race_date'])\n",
    "    df = df.rename(columns={'distance_id': 'race_distance'})\n",
    "\n",
    "    df['previous_race_date'] = df.groupby('registration_number')['race_date'].shift(1)\n",
    "    df['previous_race_dnf'] = df.groupby('registration_number')['dnf'].shift(1)\n",
    "    df['previous_race_scratch'] = df.groupby('registration_number')['scratched'].shift(1)\n",
    "    df['previous_race_distance'] = df.groupby('registration_number')['race_distance'].shift(1)\n",
    "    df['previous_surface'] = df.groupby('registration_number')['surface'].shift(1)\n",
    "    df['days_since_last_race'] = (df['race_date'] - df['previous_race_date']).dt.days\n",
    "\n",
    "\n",
    "    df['distance_delta'] = df['race_distance'] - df['previous_race_distance']\n",
    "    df['distance_jump'] = np.where(\n",
    "        df['distance_delta'] > 200,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df['rest_after_dnf'] = np.where(\n",
    "        df['previous_race_dnf'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['rest_after_scratch'] = np.where(\n",
    "        df['previous_race_scratch'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['surface_change'] = np.where(\n",
    "        df['surface'] != df['previous_surface'],\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # maybe should account for covid\n",
    "    df['long_layoff'] = np.where(\n",
    "        df['days_since_last_race'] > 365,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_params(grouped_df: pd.DataFrame) -> pd.Series:\n",
    "    try:\n",
    "        params = lognorm.fit(grouped_df['days_since_last_race'].dropna())\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        params = (None, None, None)\n",
    "\n",
    "    trainer_params = pd.Series(params, index=['lognorm_p1', 'lognorm_p2', 'lognorm_p3'])\n",
    "    \n",
    "    return trainer_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_long(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    first_long = df[df['race_distance'] > 800].sort_values(by=['race_date']).groupby(['registration_number', 'trainer_id']).first().reset_index()\n",
    "\n",
    "    \n",
    "    trainer_first_long = first_long.groupby(['trainer_id']).agg({\n",
    "            'age': 'median'\n",
    "        }).reset_index().rename(columns={'age': 'first_long_age'})\n",
    "\n",
    "    return trainer_first_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_trainer_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    trainers = df.groupby(['trainer_id']).agg({\n",
    "        'race_number': 'count',\n",
    "        'registration_number': 'nunique',\n",
    "        'scratched': 'sum',\n",
    "        'dnf': 'sum',\n",
    "        'age': 'min',\n",
    "        'lasix': 'sum',\n",
    "        'bute': 'sum',\n",
    "        'days_since_last_race': ['min', 'median'],\n",
    "        'rest_after_dnf': 'median',\n",
    "        'rest_after_scratch': 'median',\n",
    "        'distance_jump': 'sum',\n",
    "        'surface_change': 'sum',\n",
    "        'long_layoff': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    trainers.columns = ['trainer_id',\n",
    "    'n_entries', 'unique_horses', 'scratched', 'dnf', 'min_age', 'lasix', 'bute', 'days_since_last_race_min', 'days_since_last_race_median', \n",
    "    'rest_after_dnf_median', 'rest_after_scratch_median', 'distance_jump', 'surface_changes', 'long_layoffs',\n",
    "    'badly_beaten'\n",
    "    ]\n",
    "\n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    trainers['lasix_pct'] = trainers['lasix'] / trainers['n_entries']\n",
    "    trainers['bute_pct'] = trainers['bute'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame, suffix: str = None) -> pd.DataFrame:\n",
    "\n",
    "    df = extract_features(df)\n",
    "    df = get_prev_race_features(df)\n",
    "    trainer_params = df.groupby('trainer_id').apply(fit_params)\n",
    "    first_long = get_first_long(df)\n",
    "    trainers = group_trainer_data(df)\n",
    "    trainers = trainers.merge(first_long, on=['trainer_id'], how='left')\n",
    "    trainers = trainers.merge(trainer_params, on=['trainer_id'], how='left')\n",
    "    \n",
    "    for c in trainers.columns:\n",
    "        if 'lognorm' in c:\n",
    "            trainers[c] = round(trainers[c], 5)\n",
    "    \n",
    "    if suffix:\n",
    "        trainers.columns = [c + f'_{suffix}' for c in trainers.columns]\n",
    "        trainers = trainers.rename(columns={\n",
    "            f'trainer_id_{suffix}': 'trainer_id'\n",
    "        })\n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(df: pd.DataFrame): \n",
    "    \n",
    "    df = extract_features(df)\n",
    "    \n",
    "    trainers = df.groupby('trainer_id').agg({\n",
    "        'race_number': 'count',\n",
    "        'dnf': 'sum',\n",
    "        'scratched': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "        #'long_layoff': 'sum',\n",
    "    })\n",
    "    \n",
    "    trainers = trainers.rename(columns={\n",
    "        'race_number': 'n_entries'\n",
    "    }).reset_index()\n",
    "    \n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    trainers = trainers[['trainer_id', 'n_entries', 'dnf_per_entry']].rename(columns={\n",
    "        'dnf_per_entry': 'target',\n",
    "        'n_entries': 'target_n_entries',\n",
    "    })\n",
    "    \n",
    "    return trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_start_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m TARGET_DAY_DELTA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m     13\u001b[0m full_model_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction_date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeature_start_dates\u001b[49m:\n\u001b[1;32m     15\u001b[0m     feature_end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(prediction_date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     feature_start_date \u001b[38;5;241m=\u001b[39m feature_end_date \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(days\u001b[38;5;241m=\u001b[39mFEATURE_DAY_DELTA)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_start_dates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_dates = [\n",
    "    '2022-07-01', \n",
    "    '2022-12-01'\n",
    "]\n",
    "\n",
    "\n",
    "df = load_data(False)\n",
    "df = get_xDNF(df)\n",
    "df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "FEATURE_DAY_DELTA = 365\n",
    "TARGET_DAY_DELTA = 180\n",
    "\n",
    "full_model_df = pd.DataFrame()\n",
    "for prediction_date in prediction_dates:\n",
    "    feature_end_date = datetime.datetime.strptime(prediction_date, '%Y-%m-%d')\n",
    "    feature_start_date = feature_end_date - datetime.timedelta(days=FEATURE_DAY_DELTA)\n",
    "    \n",
    "    target_start_date = feature_end_date + datetime.timedelta(days=1)\n",
    "    target_end_date = target_start_date + datetime.timedelta(days=TARGET_DAY_DELTA)\n",
    "    \n",
    "    df_features = df[(df['race_date'] >= feature_start_date) & (df['race_date'] <= feature_end_date)]\n",
    "    df_target = df[(df['race_date'] >= target_start_date) & (df['race_date'] <= target_end_date)]\n",
    "    \n",
    "    features = create_features(df_features, str(FEATURE_DAY_DELTA))\n",
    "    targets = create_targets(df_target)\n",
    "    \n",
    "    df_date = features.merge(targets, how='inner', on='trainer_id')\n",
    "    full_model_df = pd.concat([full_model_df, df_date], ignore_index=True)\n",
    "    \n",
    "\n",
    "for n_entries in [50, 100, 250]:\n",
    "    # for each n_entries, group by trainer id and keep the most recent n_entries\n",
    "    # then create features and targets\n",
    "\n",
    "    df_features = df.groupby('trainer_id').apply(lambda x: x.tail(n_entries)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_builds import build_xgb_regressor, build_linear_regressor\n",
    "from baseline_model.preprocessing import create_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_train_test_split(full_model_df, test_size=0.2, valid_size=0.1, split_column='trainer_id')\n",
    "\n",
    "lin_reg_model = build_linear_regressor(data)\n",
    "#xgb_model = build_xgb_classifier(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "\n",
    "## Baseline Model\n",
    "- lambda\n",
    "\n",
    "\n",
    "## Risk Model\n",
    "- preprocess\n",
    "    - distance\n",
    "    - beyer? \n",
    "    - smoothed values\n",
    "\n",
    "- workouts\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['previous_performance_figure'] = df.groupby('registration_number')['performance_figure'].shift(1)\n",
    "df['performance_figure'] = df['performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "df['previous_performance_figure'] = df['previous_performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "\n",
    "prev_perf = df.dropna(subset=['previous_performance_figure', 'performance_figure'])\n",
    "prev_perf = prev_perf[(prev_perf['previous_performance_figure']) > 0 & (prev_perf['performance_figure'] > 0)]\n",
    "prev_perf['performance_figure_ratio'] = prev_perf['performance_figure'] / prev_perf['previous_performance_figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model.load_data import load_data\n",
    "from baseline_model.preprocessing import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(True)\n",
    "df = preprocess_data(df)\n",
    "df = df.drop(columns=['dnf', 'registration_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/models/baseline_log_reg_model.pkl', 'rb') as f:\n",
    "    log_reg_model = pickle.load(f)\n",
    "\n",
    "with open('output/models/baseline_xgb_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(log_reg_model.feature_names_in_, log_reg_model.coef_[0]):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(xgb_model.feature_names_in_, xgb_model.feature_importances_):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shap to get feature importance\n",
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(df[xgb_model.feature_names_in_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values\n",
    "shap.summary_plot(shap_values, df[xgb_model.feature_names_in_], plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values for a single prediction\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], df[xgb_model.feature_names_in_].iloc[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shap for two features\n",
    "shap.dependence_plot('surface_D', shap_values, df[xgb_model.feature_names_in_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs actual color cmap by data['target_n_entries]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xgb_model.predict(df[xgb_model.feature_names_in_]), df['target'], c=df['target_n_entries'], cmap='viridis')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "# add r2 score to plot\n",
    "plt.text(0.1, 0.9, f'R2: {xgb_model.score(df[xgb_model.feature_names_in_], df[\"target\"])}', fontsize=12)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(preds, bins=30)\n",
    "# vertical black dotted line for mean\n",
    "plt.axvline(np.mean(preds), color='black', linestyle='--')\n",
    "# red dotted lines at +1 and -1 stdev \n",
    "plt.axvline(np.mean(preds) + np.std(preds), color='red', linestyle='--')\n",
    "plt.axvline(np.mean(preds) - np.std(preds), color='red', linestyle='--')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predictions Histogram')\n",
    "\n",
    "# add text in upper right with mean and stdev\n",
    "# only show 3 decimal places\n",
    "plt.text(0.6, 0.9, f'Mean: {np.mean(preds):.3f}', fontsize=12, transform=plt.gcf().transFigure)\n",
    "plt.text(0.6, 0.85, f'Stdev: {np.std(preds):.3f}', fontsize=12, transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/users/jameshull/documents/github/hisa-data/test_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_date</th>\n",
       "      <th>track_id</th>\n",
       "      <th>race_number</th>\n",
       "      <th>race_type</th>\n",
       "      <th>distance_id</th>\n",
       "      <th>distance_unit</th>\n",
       "      <th>surface</th>\n",
       "      <th>course_type</th>\n",
       "      <th>track_condition</th>\n",
       "      <th>weather</th>\n",
       "      <th>...</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>trouble_indicator</th>\n",
       "      <th>scratch_indicator</th>\n",
       "      <th>scratch_reason</th>\n",
       "      <th>short_comment</th>\n",
       "      <th>long_comment</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>AQU</td>\n",
       "      <td>2</td>\n",
       "      <td>ALW</td>\n",
       "      <td>600</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>FT</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>248028</td>\n",
       "      <td>2303261</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>prompted 3w, weakened</td>\n",
       "      <td>prompted 3w, coaxed 5/16, 4w upper, weakened</td>\n",
       "      <td>Bezos</td>\n",
       "      <td>H</td>\n",
       "      <td>5.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>AQU</td>\n",
       "      <td>2</td>\n",
       "      <td>ALW</td>\n",
       "      <td>600</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>FT</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>957331</td>\n",
       "      <td>1586302</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>7w upper, improved</td>\n",
       "      <td>brk in st, chased 2p, coaxed 3/8, angled 7w up...</td>\n",
       "      <td>Who Hoo Thats Me</td>\n",
       "      <td>H</td>\n",
       "      <td>4.802739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             race_date track_id  race_number race_type  distance_id  \\\n",
       "0  2024-01-01 00:00:00      AQU            2       ALW          600   \n",
       "1  2024-01-01 00:00:00      AQU            2       ALW          600   \n",
       "\n",
       "  distance_unit surface course_type track_condition weather  ... trainer_id  \\\n",
       "0             F       D           D             FT        L  ...     248028   \n",
       "1             F       D           D             FT        L  ...     957331   \n",
       "\n",
       "  owner_id trouble_indicator scratch_indicator  scratch_reason  \\\n",
       "0  2303261                 N                 N                   \n",
       "1  1586302                 N                 N                   \n",
       "\n",
       "           short_comment                                       long_comment  \\\n",
       "0  prompted 3w, weakened       prompted 3w, coaxed 5/16, 4w upper, weakened   \n",
       "1     7w upper, improved  brk in st, chased 2p, coaxed 3/8, angled 7w up...   \n",
       "\n",
       "         horse_name  sex       age  \n",
       "0             Bezos    H  5.876712  \n",
       "1  Who Hoo Thats Me    H  4.802739  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    0.920389\n",
       "Y    0.079611\n",
       "Name: trouble_indicator, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trouble_indicator'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26       bumped start, set pressured pace inside, kicke...\n",
       "32       bumped start, pressed pace between horses, won...\n",
       "35       set pressured pace 3-2 wide, headed turn, bump...\n",
       "39       tracked between, in tight 7/16, bumped rival 1...\n",
       "48       bumped start, chased 2 wide, came 5 wide, need...\n",
       "                               ...                        \n",
       "26016             chased,4wd turn,forced out 1/8,flattened\n",
       "26017    bobbled break,stalked 2&3p,challenged 3/8,up 1...\n",
       "26039      very fractious gate, 2nd flight 2-3w btw, tired\n",
       "26047    jostled, closed quarters, bumped, swung 6w, gr...\n",
       "26096    stalked pace, rally 3w, angled in, off heels, ...\n",
       "Name: long_comment, Length: 2078, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['trouble_indicator'] == 'Y']['long_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

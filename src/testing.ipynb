{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xDNF(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    scratches = df[df['scratch_indicator'] == 'Y']\n",
    "    scratches['xDNF'] = np.nan\n",
    "    racers = df[df['scratch_indicator'] != 'Y']\n",
    "    racers['xDNF'] = baseline_inference(df)\n",
    "\n",
    "    df = pd.concat([racers, scratches])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit exponential to df['length_behind_at_finish']\n",
    "from scipy.stats import expon\n",
    "\n",
    "params = expon.fit(df['length_behind_at_finish'])\n",
    "\n",
    "# get 95th percentile\n",
    "expon.ppf(0.95, *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_race_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "    df = df.sort_values(by=['registration_number', 'race_date'])\n",
    "    df = df.rename(columns={'distance_id': 'race_distance'})\n",
    "\n",
    "    df['previous_race_date'] = df.groupby('registration_number')['race_date'].shift(1)\n",
    "    df['previous_race_dnf'] = df.groupby('registration_number')['dnf'].shift(1)\n",
    "    df['previous_race_scratch'] = df.groupby('registration_number')['scratched'].shift(1)\n",
    "    df['previous_race_distance'] = df.groupby('registration_number')['race_distance'].shift(1)\n",
    "    df['previous_surface'] = df.groupby('registration_number')['surface'].shift(1)\n",
    "    df['days_since_last_race'] = (df['race_date'] - df['previous_race_date']).dt.days\n",
    "\n",
    "\n",
    "    df['distance_delta'] = df['race_distance'] - df['previous_race_distance']\n",
    "    df['distance_jump'] = np.where(\n",
    "        df['distance_delta'] > 200,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df['rest_after_dnf'] = np.where(\n",
    "        df['previous_race_dnf'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['rest_after_scratch'] = np.where(\n",
    "        df['previous_race_scratch'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['surface_change'] = np.where(\n",
    "        df['surface'] != df['previous_surface'],\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # maybe should account for covid\n",
    "    df['long_layoff'] = np.where(\n",
    "        df['days_since_last_race'] > 365,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_params(grouped_df: pd.DataFrame) -> pd.Series:\n",
    "    try:\n",
    "        params = lognorm.fit(grouped_df['days_since_last_race'].dropna())\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        params = (None, None, None)\n",
    "\n",
    "    trainer_params = pd.Series(params, index=['lognorm_p1', 'lognorm_p2', 'lognorm_p3'])\n",
    "    \n",
    "    return trainer_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_long(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    first_long = df[df['race_distance'] > 800].sort_values(by=['race_date']).groupby(['registration_number', 'trainer_id']).first().reset_index()\n",
    "\n",
    "    \n",
    "    trainer_first_long = first_long.groupby(['trainer_id']).agg({\n",
    "            'age': 'median'\n",
    "        }).reset_index().rename(columns={'age': 'first_long_age'})\n",
    "\n",
    "    return trainer_first_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_trainer_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    trainers = df.groupby(['trainer_id']).agg({\n",
    "        'race_number': 'count',\n",
    "        'registration_number': 'nunique',\n",
    "        'scratched': 'sum',\n",
    "        'dnf': 'sum',\n",
    "        'age': 'min',\n",
    "        'lasix': 'sum',\n",
    "        'bute': 'sum',\n",
    "        'days_since_last_race': ['min', 'median'],\n",
    "        'rest_after_dnf': 'median',\n",
    "        'rest_after_scratch': 'median',\n",
    "        'distance_jump': 'sum',\n",
    "        'surface_change': 'sum',\n",
    "        'long_layoff': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    trainers.columns = ['trainer_id',\n",
    "    'n_entries', 'unique_horses', 'scratched', 'dnf', 'min_age', 'lasix', 'bute', 'days_since_last_race_min', 'days_since_last_race_median', \n",
    "    'rest_after_dnf_median', 'rest_after_scratch_median', 'distance_jump', 'surface_changes', 'long_layoffs',\n",
    "    'badly_beaten'\n",
    "    ]\n",
    "\n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    trainers['lasix_pct'] = trainers['lasix'] / trainers['n_entries']\n",
    "    trainers['bute_pct'] = trainers['bute'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame, suffix: str = None) -> pd.DataFrame:\n",
    "\n",
    "    df = extract_features(df)\n",
    "    df = get_prev_race_features(df)\n",
    "    trainer_params = df.groupby('trainer_id').apply(fit_params)\n",
    "    first_long = get_first_long(df)\n",
    "    trainers = group_trainer_data(df)\n",
    "    trainers = trainers.merge(first_long, on=['trainer_id'], how='left')\n",
    "    trainers = trainers.merge(trainer_params, on=['trainer_id'], how='left')\n",
    "    \n",
    "    for c in trainers.columns:\n",
    "        if 'lognorm' in c:\n",
    "            trainers[c] = round(trainers[c], 5)\n",
    "    \n",
    "    if suffix:\n",
    "        trainers.columns = [c + f'_{suffix}' for c in trainers.columns]\n",
    "        trainers = trainers.rename(columns={\n",
    "            f'trainer_id_{suffix}': 'trainer_id'\n",
    "        })\n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(df: pd.DataFrame): \n",
    "    \n",
    "    df = extract_features(df)\n",
    "    \n",
    "    trainers = df.groupby('trainer_id').agg({\n",
    "        'race_number': 'count',\n",
    "        'dnf': 'sum',\n",
    "        'scratched': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "        #'long_layoff': 'sum',\n",
    "    })\n",
    "    \n",
    "    trainers = trainers.rename(columns={\n",
    "        'race_number': 'n_entries'\n",
    "    }).reset_index()\n",
    "    \n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    trainers = trainers[['trainer_id', 'n_entries', 'dnf_per_entry']].rename(columns={\n",
    "        'dnf_per_entry': 'target',\n",
    "        'n_entries': 'target_n_entries',\n",
    "    })\n",
    "    \n",
    "    return trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_start_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m TARGET_DAY_DELTA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m     13\u001b[0m full_model_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction_date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeature_start_dates\u001b[49m:\n\u001b[1;32m     15\u001b[0m     feature_end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(prediction_date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     feature_start_date \u001b[38;5;241m=\u001b[39m feature_end_date \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(days\u001b[38;5;241m=\u001b[39mFEATURE_DAY_DELTA)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_start_dates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_dates = [\n",
    "    '2022-07-01', \n",
    "    '2022-12-01'\n",
    "]\n",
    "\n",
    "\n",
    "df = load_data(False)\n",
    "df = get_xDNF(df)\n",
    "df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "FEATURE_DAY_DELTA = 365\n",
    "TARGET_DAY_DELTA = 180\n",
    "\n",
    "full_model_df = pd.DataFrame()\n",
    "for prediction_date in prediction_dates:\n",
    "    feature_end_date = datetime.datetime.strptime(prediction_date, '%Y-%m-%d')\n",
    "    feature_start_date = feature_end_date - datetime.timedelta(days=FEATURE_DAY_DELTA)\n",
    "    \n",
    "    target_start_date = feature_end_date + datetime.timedelta(days=1)\n",
    "    target_end_date = target_start_date + datetime.timedelta(days=TARGET_DAY_DELTA)\n",
    "    \n",
    "    df_features = df[(df['race_date'] >= feature_start_date) & (df['race_date'] <= feature_end_date)]\n",
    "    df_target = df[(df['race_date'] >= target_start_date) & (df['race_date'] <= target_end_date)]\n",
    "    \n",
    "    features = create_features(df_features, str(FEATURE_DAY_DELTA))\n",
    "    targets = create_targets(df_target)\n",
    "    \n",
    "    df_date = features.merge(targets, how='inner', on='trainer_id')\n",
    "    full_model_df = pd.concat([full_model_df, df_date], ignore_index=True)\n",
    "    \n",
    "\n",
    "for n_entries in [50, 100, 250]:\n",
    "    # for each n_entries, group by trainer id and keep the most recent n_entries\n",
    "    # then create features and targets\n",
    "\n",
    "    df_features = df.groupby('trainer_id').apply(lambda x: x.tail(n_entries)).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_builds import build_xgb_regressor, build_linear_regressor\n",
    "from baseline_model.preprocessing import create_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_train_test_split(full_model_df, test_size=0.2, valid_size=0.1, split_column='trainer_id')\n",
    "\n",
    "lin_reg_model = build_linear_regressor(data)\n",
    "#xgb_model = build_xgb_classifier(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "\n",
    "## Baseline Model\n",
    "- lambda\n",
    "\n",
    "\n",
    "## Risk Model\n",
    "- preprocess\n",
    "    - distance\n",
    "    - beyer? \n",
    "    - smoothed values\n",
    "\n",
    "- workouts\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['previous_performance_figure'] = df.groupby('registration_number')['performance_figure'].shift(1)\n",
    "df['performance_figure'] = df['performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "df['previous_performance_figure'] = df['previous_performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "\n",
    "prev_perf = df.dropna(subset=['previous_performance_figure', 'performance_figure'])\n",
    "prev_perf = prev_perf[(prev_perf['previous_performance_figure']) > 0 & (prev_perf['performance_figure'] > 0)]\n",
    "prev_perf['performance_figure_ratio'] = prev_perf['performance_figure'] / prev_perf['previous_performance_figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model.load_data import load_data\n",
    "from baseline_model.preprocessing import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(True)\n",
    "df = preprocess_data(df)\n",
    "df = df.drop(columns=['dnf', 'registration_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/models/baseline_log_reg_model.pkl', 'rb') as f:\n",
    "    log_reg_model = pickle.load(f)\n",
    "\n",
    "with open('output/models/baseline_xgb_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(log_reg_model.feature_names_in_, log_reg_model.coef_[0]):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(xgb_model.feature_names_in_, xgb_model.feature_importances_):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shap to get feature importance\n",
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(df[xgb_model.feature_names_in_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values\n",
    "shap.summary_plot(shap_values, df[xgb_model.feature_names_in_], plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values for a single prediction\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], df[xgb_model.feature_names_in_].iloc[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shap for two features\n",
    "shap.dependence_plot('surface_D', shap_values, df[xgb_model.feature_names_in_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs actual color cmap by data['target_n_entries]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(xgb_model.predict(df[xgb_model.feature_names_in_]), df['target'], c=df['target_n_entries'], cmap='viridis')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "# add r2 score to plot\n",
    "plt.text(0.1, 0.9, f'R2: {xgb_model.score(df[xgb_model.feature_names_in_], df[\"target\"])}', fontsize=12)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(preds, bins=30)\n",
    "# vertical black dotted line for mean\n",
    "plt.axvline(np.mean(preds), color='black', linestyle='--')\n",
    "# red dotted lines at +1 and -1 stdev \n",
    "plt.axvline(np.mean(preds) + np.std(preds), color='red', linestyle='--')\n",
    "plt.axvline(np.mean(preds) - np.std(preds), color='red', linestyle='--')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predictions Histogram')\n",
    "\n",
    "# add text in upper right with mean and stdev\n",
    "# only show 3 decimal places\n",
    "plt.text(0.6, 0.9, f'Mean: {np.mean(preds):.3f}', fontsize=12, transform=plt.gcf().transFigure)\n",
    "plt.text(0.6, 0.85, f'Stdev: {np.std(preds):.3f}', fontsize=12, transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/users/jameshull/documents/github/hisa-data/test_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_date</th>\n",
       "      <th>track_id</th>\n",
       "      <th>race_number</th>\n",
       "      <th>race_type</th>\n",
       "      <th>distance_id</th>\n",
       "      <th>distance_unit</th>\n",
       "      <th>surface</th>\n",
       "      <th>course_type</th>\n",
       "      <th>track_condition</th>\n",
       "      <th>weather</th>\n",
       "      <th>...</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>trouble_indicator</th>\n",
       "      <th>scratch_indicator</th>\n",
       "      <th>scratch_reason</th>\n",
       "      <th>short_comment</th>\n",
       "      <th>long_comment</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>AQU</td>\n",
       "      <td>2</td>\n",
       "      <td>ALW</td>\n",
       "      <td>600</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>FT</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>248028</td>\n",
       "      <td>2303261</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>prompted 3w, weakened</td>\n",
       "      <td>prompted 3w, coaxed 5/16, 4w upper, weakened</td>\n",
       "      <td>Bezos</td>\n",
       "      <td>H</td>\n",
       "      <td>5.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>AQU</td>\n",
       "      <td>2</td>\n",
       "      <td>ALW</td>\n",
       "      <td>600</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>FT</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>957331</td>\n",
       "      <td>1586302</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>7w upper, improved</td>\n",
       "      <td>brk in st, chased 2p, coaxed 3/8, angled 7w up...</td>\n",
       "      <td>Who Hoo Thats Me</td>\n",
       "      <td>H</td>\n",
       "      <td>4.802739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             race_date track_id  race_number race_type  distance_id  \\\n",
       "0  2024-01-01 00:00:00      AQU            2       ALW          600   \n",
       "1  2024-01-01 00:00:00      AQU            2       ALW          600   \n",
       "\n",
       "  distance_unit surface course_type track_condition weather  ... trainer_id  \\\n",
       "0             F       D           D             FT        L  ...     248028   \n",
       "1             F       D           D             FT        L  ...     957331   \n",
       "\n",
       "  owner_id trouble_indicator scratch_indicator  scratch_reason  \\\n",
       "0  2303261                 N                 N                   \n",
       "1  1586302                 N                 N                   \n",
       "\n",
       "           short_comment                                       long_comment  \\\n",
       "0  prompted 3w, weakened       prompted 3w, coaxed 5/16, 4w upper, weakened   \n",
       "1     7w upper, improved  brk in st, chased 2p, coaxed 3/8, angled 7w up...   \n",
       "\n",
       "         horse_name  sex       age  \n",
       "0             Bezos    H  5.876712  \n",
       "1  Who Hoo Thats Me    H  4.802739  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    0.920389\n",
       "Y    0.079611\n",
       "Name: trouble_indicator, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trouble_indicator'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26       bumped start, set pressured pace inside, kicke...\n",
       "32       bumped start, pressed pace between horses, won...\n",
       "35       set pressured pace 3-2 wide, headed turn, bump...\n",
       "39       tracked between, in tight 7/16, bumped rival 1...\n",
       "48       bumped start, chased 2 wide, came 5 wide, need...\n",
       "                               ...                        \n",
       "26016             chased,4wd turn,forced out 1/8,flattened\n",
       "26017    bobbled break,stalked 2&3p,challenged 3/8,up 1...\n",
       "26039      very fractious gate, 2nd flight 2-3w btw, tired\n",
       "26047    jostled, closed quarters, bumped, swung 6w, gr...\n",
       "26096    stalked pace, rally 3w, angled in, off heels, ...\n",
       "Name: long_comment, Length: 2078, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['trouble_indicator'] == 'Y']['long_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BADLY_BEATEN_THRESHOLD = 2490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.22.4)\r\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from xgboost) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model.load_data import load_data\n",
    "from baseline_model.inference import baseline_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xDNF(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    scratches = df[df['scratch_indicator'] == 'Y']\n",
    "    scratches['xDNF'] = np.nan\n",
    "    racers = df[df['scratch_indicator'] != 'Y']\n",
    "    racers['xDNF'] = baseline_inference(df)\n",
    "\n",
    "    df = pd.concat([racers, scratches])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['dnf'] = np.where(\n",
    "        (df['trouble_indicator'] == 'Y') | (df['length_behind_at_finish'] == 9999),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df['scratched'] = np.where(\n",
    "        df['scratch_indicator'] == 'Y',\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['lasix'] = np.where(\n",
    "        df['medication'].str.contains('L'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['bute'] = np.where(\n",
    "        df['medication'].str.contains('B'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    df['badly_beaten'] = np.where(\n",
    "        (df['length_behind_at_finish'] > BADLY_BEATEN_THRESHOLD) & (df['length_behind_at_finish'] < 9000),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_race_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "    df = df.sort_values(by=['registration_number', 'race_date'])\n",
    "    df = df.rename(columns={'distance_id': 'race_distance'})\n",
    "\n",
    "    df['previous_race_date'] = df.groupby('registration_number')['race_date'].shift(1)\n",
    "    df['previous_race_dnf'] = df.groupby('registration_number')['dnf'].shift(1)\n",
    "    df['previous_race_scratch'] = df.groupby('registration_number')['scratched'].shift(1)\n",
    "    df['previous_race_distance'] = df.groupby('registration_number')['race_distance'].shift(1)\n",
    "    df['previous_surface'] = df.groupby('registration_number')['surface'].shift(1)\n",
    "    df['days_since_last_race'] = (df['race_date'] - df['previous_race_date']).dt.days\n",
    "\n",
    "\n",
    "    df['distance_delta'] = df['race_distance'] - df['previous_race_distance']\n",
    "    df['distance_jump'] = np.where(\n",
    "        df['distance_delta'] > 200,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    df['rest_after_dnf'] = np.where(\n",
    "        df['previous_race_dnf'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['rest_after_scratch'] = np.where(\n",
    "        df['previous_race_scratch'] == 1,\n",
    "        df['days_since_last_race'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df['surface_change'] = np.where(\n",
    "        df['surface'] != df['previous_surface'],\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # maybe should account for covid\n",
    "    df['long_layoff'] = np.where(\n",
    "        df['days_since_last_race'] > 365,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_params(grouped_df: pd.DataFrame) -> pd.Series:\n",
    "    try:\n",
    "        params = lognorm.fit(grouped_df['days_since_last_race'].dropna())\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        params = (None, None, None)\n",
    "\n",
    "    trainer_params = pd.Series(params, index=['lognorm_p1', 'lognorm_p2', 'lognorm_p3'])\n",
    "    \n",
    "    return trainer_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_long(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    first_long = df[df['race_distance'] > 800].sort_values(by=['race_date']).groupby(['registration_number', 'trainer_id']).first().reset_index()\n",
    "\n",
    "    \n",
    "    trainer_first_long = first_long.groupby(['trainer_id']).agg({\n",
    "            'age': 'median'\n",
    "        }).reset_index().rename(columns={'age': 'first_long_age'})\n",
    "\n",
    "    return trainer_first_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_trainer_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    trainers = df.groupby(['trainer_id']).agg({\n",
    "        'race_number': 'count',\n",
    "        'registration_number': 'nunique',\n",
    "        'scratched': 'sum',\n",
    "        'dnf': 'sum',\n",
    "        'age': 'min',\n",
    "        'lasix': 'sum',\n",
    "        'bute': 'sum',\n",
    "        'days_since_last_race': ['min', 'median'],\n",
    "        'rest_after_dnf': 'median',\n",
    "        'rest_after_scratch': 'median',\n",
    "        'distance_jump': 'sum',\n",
    "        'surface_change': 'sum',\n",
    "        'long_layoff': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "    }).reset_index()\n",
    "\n",
    "    trainers.columns = ['trainer_id',\n",
    "    'n_entries', 'unique_horses', 'scratched', 'dnf', 'min_age', 'lasix', 'bute', 'days_since_last_race_min', 'days_since_last_race_median', \n",
    "    'rest_after_dnf_median', 'rest_after_scratch_median', 'distance_jump', 'surface_changes', 'long_layoffs',\n",
    "    'badly_beaten'\n",
    "    ]\n",
    "\n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    trainers['lasix_pct'] = trainers['lasix'] / trainers['n_entries']\n",
    "    trainers['bute_pct'] = trainers['bute'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame, suffix: str = None) -> pd.DataFrame:\n",
    "\n",
    "    df = extract_features(df)\n",
    "    df = get_prev_race_features(df)\n",
    "    trainer_params = df.groupby('trainer_id').apply(fit_params)\n",
    "    first_long = get_first_long(df)\n",
    "    trainers = group_trainer_data(df)\n",
    "    trainers = trainers.merge(first_long, on=['trainer_id'], how='left')\n",
    "    trainers = trainers.merge(trainer_params, on=['trainer_id'], how='left')\n",
    "    \n",
    "    for c in trainers.columns:\n",
    "        if 'lognorm' in c:\n",
    "            trainers[c] = round(trainers[c], 5)\n",
    "    \n",
    "    if suffix:\n",
    "        trainers.columns = [c + f'_{suffix}' for c in trainers.columns]\n",
    "        trainers = trainers.rename(columns={\n",
    "            f'trainer_id_{suffix}': 'trainer_id'\n",
    "        })\n",
    "    \n",
    "    return trainers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(df: pd.DataFrame): \n",
    "    \n",
    "    df = extract_features(df)\n",
    "    \n",
    "    trainers = df.groupby('trainer_id').agg({\n",
    "        'race_number': 'count',\n",
    "        'dnf': 'sum',\n",
    "        'scratched': 'sum',\n",
    "        'badly_beaten': 'sum',\n",
    "        #'long_layoff': 'sum',\n",
    "    })\n",
    "    \n",
    "    trainers = trainers.rename(columns={\n",
    "        'race_number': 'n_entries'\n",
    "    }).reset_index()\n",
    "    \n",
    "    trainers['scratches_per_entry'] = trainers['scratched'] / trainers['n_entries']\n",
    "    trainers['dnf_per_entry'] = trainers['dnf'] / trainers['n_entries']\n",
    "    trainers['badly_beaten_pct'] = trainers['badly_beaten'] / trainers['n_entries']\n",
    "    \n",
    "    # TODO\n",
    "    # trainers['dnf_per_entry_smooth'] = None\n",
    "    # trainers['scratches_per_entry'] = None\n",
    "    \n",
    "    trainers = trainers[['trainer_id', 'n_entries', 'dnf_per_entry']].rename(columns={\n",
    "        'dnf_per_entry': 'target',\n",
    "        'n_entries': 'target_n_entries',\n",
    "    })\n",
    "    \n",
    "    return trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_start_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m TARGET_DAY_DELTA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m     13\u001b[0m full_model_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction_date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeature_start_dates\u001b[49m:\n\u001b[1;32m     15\u001b[0m     feature_end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(prediction_date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     feature_start_date \u001b[38;5;241m=\u001b[39m feature_end_date \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtimedelta(days\u001b[38;5;241m=\u001b[39mFEATURE_DAY_DELTA)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_start_dates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_dates = [\n",
    "    '2022-07-01', \n",
    "    '2022-12-01'\n",
    "]\n",
    "\n",
    "\n",
    "df = load_data(False)\n",
    "df = get_xDNF(df)\n",
    "df['race_date'] = pd.to_datetime(df['race_date'])\n",
    "FEATURE_DAY_DELTA = 365\n",
    "TARGET_DAY_DELTA = 180\n",
    "\n",
    "full_model_df = pd.DataFrame()\n",
    "for prediction_date in prediction_dates:\n",
    "    feature_end_date = datetime.datetime.strptime(prediction_date, '%Y-%m-%d')\n",
    "    feature_start_date = feature_end_date - datetime.timedelta(days=FEATURE_DAY_DELTA)\n",
    "    \n",
    "    target_start_date = feature_end_date + datetime.timedelta(days=1)\n",
    "    target_end_date = target_start_date + datetime.timedelta(days=TARGET_DAY_DELTA)\n",
    "    \n",
    "    df_features = df[(df['race_date'] >= feature_start_date) & (df['race_date'] <= feature_end_date)]\n",
    "    df_target = df[(df['race_date'] >= target_start_date) & (df['race_date'] <= target_end_date)]\n",
    "    \n",
    "    features = create_features(df_features, str(FEATURE_DAY_DELTA))\n",
    "    targets = create_targets(df_target)\n",
    "    \n",
    "    df_date = features.merge(targets, how='inner', on='trainer_id')\n",
    "    full_model_df = pd.concat([full_model_df, df_date], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_builds import build_xgb_regressor, build_linear_regressor\n",
    "from baseline_model.preprocessing import create_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_train_test_split(full_model_df, test_size=0.2, valid_size=0.1, split_column='trainer_id')\n",
    "\n",
    "lin_reg_model = build_linear_regressor(data)\n",
    "#xgb_model = build_xgb_classifier(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "\n",
    "## Baseline Model\n",
    "- lambda\n",
    "\n",
    "\n",
    "## Risk Model\n",
    "- preprocess\n",
    "    - distance\n",
    "    - beyer\n",
    "    - smoothed values\n",
    "\n",
    "- workouts\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['previous_performance_figure'] = df.groupby('registration_number')['performance_figure'].shift(1)\n",
    "df['performance_figure'] = df['performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "df['previous_performance_figure'] = df['previous_performance_figure'].str.replace('-', '0').astype(float, errors='ignore')\n",
    "\n",
    "prev_perf = df.dropna(subset=['previous_performance_figure', 'performance_figure'])\n",
    "prev_perf = prev_perf[(prev_perf['previous_performance_figure']) > 0 & (prev_perf['performance_figure'] > 0)]\n",
    "prev_perf['performance_figure_ratio'] = prev_perf['performance_figure'] / prev_perf['previous_performance_figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model.load_data import load_data\n",
    "from baseline_model.preprocessing import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(True)\n",
    "df = preprocess_data(df)\n",
    "df = df.drop(columns=['dnf', 'registration_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/models/baseline_log_reg_model.pkl', 'rb') as f:\n",
    "    log_reg_model = pickle.load(f)\n",
    "\n",
    "with open('output/models/baseline_xgb_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(log_reg_model.feature_names_in_, log_reg_model.coef_[0]):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_imp = []\n",
    "for col, coef in zip(xgb_model.feature_names_in_, xgb_model.feature_importances_):\n",
    "    ft_imp.append({\n",
    "        'feature': col,\n",
    "        'importance': coef\n",
    "    })\n",
    "\n",
    "ft_imp = pd.DataFrame(ft_imp)\n",
    "ft_imp = ft_imp.sort_values(by='importance')\n",
    "\n",
    "plt.barh(ft_imp['feature'], ft_imp['importance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shap to get feature importance\n",
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(df[xgb_model.feature_names_in_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values\n",
    "shap.summary_plot(shap_values, df[xgb_model.feature_names_in_], plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SHAP values for a single prediction\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], df[xgb_model.feature_names_in_].iloc[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shap for two features\n",
    "shap.dependence_plot('surface_D', shap_values, df[xgb_model.feature_names_in_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
